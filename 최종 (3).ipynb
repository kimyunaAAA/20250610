{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWfS4YrqLjEj",
        "outputId": "138e66b5-3381-4dfb-95d7-303a545ec636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-comment-downloader\n",
            "  Downloading youtube_comment_downloader-0.1.76-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dateparser (from youtube-comment-downloader)\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-comment-downloader) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->youtube-comment-downloader) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-comment-downloader) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser->youtube-comment-downloader) (1.17.0)\n",
            "Downloading youtube_comment_downloader-0.1.76-py3-none-any.whl (8.2 kB)\n",
            "Downloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dateparser, youtube-comment-downloader\n",
            "Successfully installed dateparser-1.2.1 youtube-comment-downloader-0.1.76\n",
            "Collecting langid\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from langid) (2.0.2)\n",
            "Building wheels for collected packages: langid\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941171 sha256=b0c607733b0e08bc1fba6bf373a9069a868becf1925c5223c84cc3b814324681\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/6a/b6/b7eb43a6ad55b139c15c5daa29f3707659cfa6944d3c696f5b\n",
            "Successfully built langid\n",
            "Installing collected packages: langid\n",
            "Successfully installed langid-1.1.6\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.11\n",
            "Requirement already satisfied: langcodes in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from marisa-trie>=1.1.0->language-data>=1.2->langcodes) (75.2.0)\n"
          ]
        }
      ],
      "source": [
        " # YouTube 댓글 다운로드를 위한 라이브러리 설치\n",
        "!pip install youtube-comment-downloader\n",
        "\n",
        "# 언어 감지를 위한 라이브러리 설치 (langid: 텍스트의 언어를 감지해주는 라이브러리)\n",
        "!pip install langid\n",
        "\n",
        "# Streamlit 설치 (Streamlit은 간단한 웹 앱을 빠르게 만들 수 있게 해주는 라이브러리)\n",
        "!pip install streamlit\n",
        "\n",
        "# ngrok을 통해 로컬 서버를 외부에서도 접속 가능하게 해주는 라이브러리 설치 (streamlit 웹앱을 배포할 때 사용 가능)\n",
        "!pip install pyngrok\n",
        "\n",
        "# 언어 코드 관련 처리를 위한 라이브러리 설치 (langcodes: ISO 639 언어 코드 관리 및 변환)\n",
        "!pip install langcodes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 버전, 지금 안 씀"
      ],
      "metadata": {
        "id": "kbFdYxLC5paz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdB8eQ1yLzX6",
        "outputId": "7c542aa2-2af7-44b2-fbf2-81b66a114c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "#지금 작성한 코드 블록을 파일로 저장해 주는 기능\n",
        "%%writefile streamlit_app.py\n",
        "\n",
        "#____________________________________________________________________________\n",
        "\n",
        "import streamlit as st  # Streamlit: 웹앱을 쉽게 만들 수 있는 라이브러리\n",
        "import os  # OS 명령어 실행용\n",
        "import json  # JSON 데이터 처리\n",
        "import pandas as pd  # 데이터프레임 처리\n",
        "import langid  # 언어 감지 라이브러리\n",
        "import langcodes  # 언어 코드 -> 언어 이름 매핑 라이브러리\n",
        "\n",
        "#____________________________________________________________________________\n",
        "\n",
        "\n",
        "# 디자인 CSS 추가: 웹앱의 배경, 폰트, 버튼 등 시각적 스타일 정의\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "/* 배경 및 글꼴 설정 */\n",
        "body {\n",
        "  margin: 0;\n",
        "  padding: 0;\n",
        "  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "  background-color: #ffffff;\n",
        "  text-align: center;\n",
        "  color: #333;\n",
        "}\n",
        "/* 중앙 로고 및 텍스트 스타일 */\n",
        ".center-box {\n",
        "  display: flex;\n",
        "  flex-direction: column;\n",
        "  justify-content: center;\n",
        "  align-items: center;\n",
        "  margin-top: 50px;\n",
        "}\n",
        ".center-box img {\n",
        "  width: 40px;\n",
        "  margin-bottom: 20px;\n",
        "}\n",
        ".center-box .title {\n",
        "  font-size: 48px;\n",
        "  color: #e60000;\n",
        "  font-weight: bold;\n",
        "  margin: 10px 0;\n",
        "}\n",
        ".center-box .subtitle {\n",
        "  font-size: 16px;\n",
        "  color: #888;\n",
        "  margin-bottom: 30px;\n",
        "}\n",
        "/* 입력란과 버튼 스타일 */\n",
        ".input-style input {\n",
        "  padding: 12px 20px;\n",
        "  width: 300px;\n",
        "  border-radius: 10px;\n",
        "  border: 1px solid #ccc;\n",
        "  font-size: 14px;\n",
        "}\n",
        ".button-style button {\n",
        "  padding: 12px 20px;\n",
        "  background-color: #e60000;\n",
        "  color: white;\n",
        "  border: none;\n",
        "  border-radius: 10px;\n",
        "  font-weight: bold;\n",
        "  cursor: pointer;\n",
        "  font-size: 14px;\n",
        "}\n",
        ".button-style button:hover {\n",
        "  background-color: #cc0000;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# 중앙 로고, 제목, 설명 표시\n",
        "st.markdown(\"\"\"\n",
        "<div class=\"center-box\">\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/YouTube_Logo_2017.svg\" alt=\"YouTube logo\" />\n",
        "  <div class=\"title\">YouniversAI</div>\n",
        "  <div class=\"subtitle\">Your smart assistant for multilingual YouTube comment insights.</div>\n",
        "</div>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "#____________________________________________________________________________\n",
        "\n",
        "\n",
        "# YouTube 댓글을 다운로드하여 DataFrame으로 반환하는 함수\n",
        "def get_comments(url):\n",
        "    json_file = 'YoutubeComments.json'\n",
        "    os.system(f'youtube-comment-downloader --url \"{url}\" --output {json_file}')  # 외부 명령어로 댓글 다운로드 (youtube-comment-downloader 사용)\n",
        "\n",
        "    # JSON 파일 읽기\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "        try:\n",
        "            json_data = json.loads(content)  # 표준 JSON 파싱\n",
        "        except json.JSONDecodeError:\n",
        "            # JSON 라인 단위 파싱 (비표준 형식 처리)\n",
        "            json_data = []\n",
        "            for line in content.splitlines():\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                try:\n",
        "                    json_data.append(json.loads(line))\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "\n",
        "    df = pd.DataFrame(json_data)  # pandas DataFrame 생성\n",
        "    os.remove(json_file)  # 임시 파일 삭제\n",
        "    return df\n",
        "\n",
        "#____________________________________________________________________________\n",
        "\n",
        "\n",
        "# 언어 감지 및 언어 이름 변환 함수\n",
        "def classify_language(df):\n",
        "    df['lang'] = df['text'].apply(lambda x: langid.classify(x)[0])  # langid로 언어코드 감지\n",
        "    df['언어'] = df['lang'].apply(lambda code: langcodes.Language.get(code).display_name() if code else code)  # 언어 코드 -> 언어명 변환\n",
        "    return df\n",
        "\n",
        "#____________________________________________________________________________\n",
        "\n",
        "# Streamlit 웹앱의 메인 함수\n",
        "def main():\n",
        "    # URL 입력란과 버튼\n",
        "    url = st.text_input(\"Paste YouTube video URL here\")\n",
        "    if st.button(\"Go\"):\n",
        "        st.write(f\"📺 You entered: {url}\")\n",
        "\n",
        "        with st.spinner(\"🔎댓글을 분류중입니다... 잠시만 기다려주세요\"):\n",
        "            df = get_comments(url)  # 댓글 가져오기\n",
        "            if df.empty or 'text' not in df.columns:\n",
        "                st.warning(\"No comments found or 'text' field missing.\")  # 오류 처리\n",
        "                return\n",
        "            df = classify_language(df)  # 언어 분류\n",
        "            st.session_state.df = df  # 세션 상태에 저장 (다른 인터랙션에서도 유지)\n",
        "\n",
        "    # 댓글 데이터가 있는 경우 출력\n",
        "    if 'df' in st.session_state:\n",
        "        df = st.session_state.df\n",
        "        st.success(\"댓글 수집 및 언어 분류 완료!\")\n",
        "        st.write(\"총 댓글 수:\", len(df))\n",
        "\n",
        "        # 언어 선택 멀티셀렉트\n",
        "        languages = df['lang'].unique().tolist()  # 언어 코드 리스트\n",
        "        language_options = [langcodes.Language.get(code).display_name() for code in languages]\n",
        "\n",
        "        selected_langs = st.multiselect(\"언어를 선택하세요\", options=language_options, default=language_options)\n",
        "\n",
        "        # 선택된 언어에 해당하는 코드 필터링\n",
        "        selected_lang_codes = [code for code in languages if langcodes.Language.get(code).display_name() in selected_langs]\n",
        "        filtered_df = df[df['lang'].isin(selected_lang_codes)]\n",
        "\n",
        "        # 선택된 언어의 댓글 출력\n",
        "        if not filtered_df.empty:\n",
        "            st.write(filtered_df[['언어', 'text']])\n",
        "        else:\n",
        "            st.warning(\"선택한 언어에 해당하는 댓글이 없습니다.\")\n",
        "\n",
        "#____________________________________________________________________________\n",
        "\n",
        "# 프로그램 시작점\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbOMkRJwGDrS"
      },
      "source": [
        "----------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6DyamhTIAsp"
      },
      "source": [
        "**디자인**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjz5XQ2RGDDs",
        "outputId": "7a74b5dc-e021-4ac2-ed54-9f953606f05f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing design.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile design.py\n",
        "import streamlit as st\n",
        "\n",
        "def apply_css():\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    body {\n",
        "      margin: 0;\n",
        "      padding: 0;\n",
        "      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "      background-color: #ffffff;\n",
        "      text-align: center;\n",
        "      color: #333;\n",
        "    }\n",
        "    .center-box {\n",
        "      display: flex;\n",
        "      flex-direction: column;\n",
        "      justify-content: center;\n",
        "      align-items: center;\n",
        "      margin-top: 50px;\n",
        "    }\n",
        "    .center-box img {\n",
        "      width: 40px;\n",
        "      margin-bottom: 20px;\n",
        "    }\n",
        "    .center-box .title {\n",
        "      font-size: 48px;\n",
        "      color: #e60000;\n",
        "      font-weight: bold;\n",
        "      margin: 10px 0;\n",
        "    }\n",
        "    .center-box .subtitle {\n",
        "      font-size: 16px;\n",
        "      color: #888;\n",
        "      margin-bottom: 30px;\n",
        "    }\n",
        "    .input-style input {\n",
        "      padding: 12px 20px;\n",
        "      width: 300px;\n",
        "      border-radius: 10px;\n",
        "      border: 1px solid #ccc;\n",
        "      font-size: 14px;\n",
        "    }\n",
        "    .button-style button {\n",
        "      padding: 12px 20px;\n",
        "      background-color: #e60000;\n",
        "      color: white;\n",
        "      border: none;\n",
        "      border-radius: 10px;\n",
        "      font-weight: bold;\n",
        "      cursor: pointer;\n",
        "      font-size: 14px;\n",
        "    }\n",
        "    .button-style button:hover {\n",
        "      background-color: #cc0000;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def show_header():\n",
        "    st.markdown(\"\"\"\n",
        "    <div class=\"center-box\">\n",
        "      <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b8/YouTube_Logo_2017.svg\" alt=\"YouTube logo\" />\n",
        "      <div class=\"title\">YouniversAI</div>\n",
        "      <div class=\"subtitle\">Your smart assistant for multilingual YouTube comment insights.</div>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5sWTgNrH_Ei"
      },
      "source": [
        "**댓글 수집**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9_5DI97H9eI",
        "outputId": "52355102-0b90-47bb-fc3d-f7f63afb7e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing logic.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile logic.py\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def get_comments(url):\n",
        "    json_file = 'YoutubeComments.json'\n",
        "    os.system(f'youtube-comment-downloader --url \"{url}\" --output {json_file}')\n",
        "\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "        try:\n",
        "            json_data = json.loads(content)\n",
        "        except json.JSONDecodeError:\n",
        "            json_data = []\n",
        "            for line in content.splitlines():\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                try:\n",
        "                    json_data.append(json.loads(line))\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "\n",
        "    df = pd.DataFrame(json_data)\n",
        "    os.remove(json_file)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-zFjsmPIEmR"
      },
      "source": [
        "**댓글 분류**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt1reUQ3IEBl",
        "outputId": "ae35c5d3-04fc-4cd0-d317-4099ecae6f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile classifier.py\n",
        "import langid\n",
        "import langcodes\n",
        "\n",
        "def classify_language(df):\n",
        "    df['lang'] = df['text'].apply(lambda x: langid.classify(x)[0])\n",
        "    df['언어'] = df['lang'].apply(\n",
        "        lambda code: langcodes.Language.get(code).display_name() if code else code)\n",
        "    return df\n",
        "\n",
        "def classify_and_store(df, session_state):\n",
        "    df = classify_language(df)\n",
        "    session_state.df = df\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh3N41DMJvWk"
      },
      "source": [
        "**요약 전용 파일**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0sodLIiJ0Vt",
        "outputId": "7dd7f535-a3a7-48a9-9e70-943124b230df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing summarizer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile summarizer.py\n",
        "import re\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from keybert import KeyBERT\n",
        "\n",
        "# 요약 모델 초기화\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"facebook/bart-large-cnn\",\n",
        "    device=-1  # CPU 모드\n",
        ")\n",
        "\n",
        "# 키워드 추출 모델 초기화\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
        "kw_model = KeyBERT(model=embed_model)\n",
        "\n",
        "def summarize_by_language(df):\n",
        "    result = {}\n",
        "    # summarizer.py 수정\n",
        "    grouped = df.groupby('lang', dropna=True)\n",
        "\n",
        "\n",
        "    for lang, group in grouped:\n",
        "        comments = group['text'].dropna().astype(str).tolist()\n",
        "        full_text = \" \".join(comments)\n",
        "\n",
        "        if len(full_text) < 50:\n",
        "            summary = \"(댓글이 너무 적어 요약 불가)\"\n",
        "            keywords = \"\"\n",
        "        else:\n",
        "            try:\n",
        "                summary = summarizer(full_text[:1500], max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
        "            except:\n",
        "                summary = \"(요약 오류 발생)\"\n",
        "            try:\n",
        "                keywords = \", \".join([kw[0] for kw in kw_model.extract_keywords(full_text)])\n",
        "            except:\n",
        "                keywords = \"\"\n",
        "\n",
        "        result[lang] = {\n",
        "            \"summary\": summary,\n",
        "            \"keywords\": keywords\n",
        "        }\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lizUKdFpRCea"
      },
      "source": [
        "**감정 분석 전용 파일**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-ceG2zeREgt",
        "outputId": "a2807f5c-207d-48d6-c0f6-593eb229f948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sentiment.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sentiment.py\n",
        "import langid\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "\n",
        "# 감정 분석 모델 초기화 (CPU 모드)\n",
        "sentiment_model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=sentiment_model,\n",
        "    tokenizer=sentiment_model,\n",
        "    truncation=True,\n",
        "    device=-1\n",
        ")\n",
        "\n",
        "# 언어 감지 함수 (간단 버전)\n",
        "def detect_langid(text):\n",
        "    try:\n",
        "        text = str(text).strip()\n",
        "        if len(text) < 2:\n",
        "            return 'unknown'\n",
        "        return langid.classify(text)[0]\n",
        "    except:\n",
        "        return 'unknown'\n",
        "\n",
        "# 감정 분석 함수\n",
        "def analyze_sentiment(df):\n",
        "    df['language'] = df['text'].apply(detect_langid)\n",
        "    dfs_by_lang = {}\n",
        "\n",
        "    for lang in df['language'].unique():\n",
        "        df_lang = df[df['language'] == lang].copy()\n",
        "        if df_lang.empty:\n",
        "            continue\n",
        "\n",
        "        comments = df_lang['text'].dropna().astype(str).tolist()\n",
        "        if not comments:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            results = sentiment_pipeline(comments)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        df_lang['sentiment'] = [r['label'] for r in results]\n",
        "        df_lang['score'] = [r['score'] for r in results]\n",
        "        df_lang['sentiment_score'] = df_lang['sentiment'].apply(lambda l: int(l.split()[0]))\n",
        "        df_lang['sentiment_kor'] = df_lang['sentiment_score'].apply(\n",
        "            lambda s: \"부정\" if s <= 2 else (\"중립\" if s == 3 else \"긍정\")\n",
        "        )\n",
        "\n",
        "        dfs_by_lang[lang] = df_lang\n",
        "\n",
        "    if not dfs_by_lang:\n",
        "        return df.copy()\n",
        "\n",
        "    return pd.concat(dfs_by_lang.values(), ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "____________________________________________________________________________"
      ],
      "metadata": {
        "id": "oqGKBmEM50HS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrzhh2YyIMik"
      },
      "source": [
        "# 메인 실행 파일"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-ArGCuUIKg7",
        "outputId": "8d43d1b0-f601-4981-c061-5c56294a7c4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import langcodes\n",
        "from design import apply_css, show_header\n",
        "from logic import get_comments\n",
        "from classifier import classify_and_store\n",
        "\n",
        "def main():\n",
        "    apply_css()\n",
        "    show_header()\n",
        "\n",
        "    url = st.text_input(\"Paste YouTube video URL here\")\n",
        "    if st.button(\"Go\"):\n",
        "        st.write(f\"📺 You entered: {url}\")\n",
        "        with st.spinner(\"🔎댓글을 분류중입니다... 잠시만 기다려주세요\"):\n",
        "            df = get_comments(url)\n",
        "            if df.empty or 'text' not in df.columns:\n",
        "                st.warning(\"No comments found or 'text' field missing.\")\n",
        "                return\n",
        "            classify_and_store(df, st.session_state)\n",
        "\n",
        "    if 'df' in st.session_state:\n",
        "        df = st.session_state.df\n",
        "        st.success(\"댓글 수집 및 언어 분류 완료!\")\n",
        "        st.write(\"총 댓글 수:\", len(df))\n",
        "\n",
        "        languages = df['lang'].unique().tolist()\n",
        "        language_options = [langcodes.Language.get(code).display_name() for code in languages]\n",
        "\n",
        "        selected_langs = st.multiselect(\"언어를 선택하세요\", options=language_options, default=language_options)\n",
        "        selected_lang_codes = [code for code in languages if langcodes.Language.get(code).display_name() in selected_langs]\n",
        "        filtered_df = df[df['lang'].isin(selected_lang_codes)]\n",
        "\n",
        "        if not filtered_df.empty:\n",
        "            st.write(filtered_df[['언어', 'text']])\n",
        "        else:\n",
        "            st.warning(\"선택한 언어에 해당하는 댓글이 없습니다.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4nQ38z1KFbb"
      },
      "source": [
        "메인 실행 파일 - 요약 전용 파일 적용 버전"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vMN3a5oKlUq",
        "outputId": "097a3e5a-ad0b-45cf-cb08-7595765c1d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m680.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install keybert sentence-transformers transformers --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9cCs_xmKJ87",
        "outputId": "b86f6698-0859-4191-edf8-329ea53f8bb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import langcodes\n",
        "from design import apply_css, show_header\n",
        "from logic import get_comments\n",
        "from classifier import classify_and_store\n",
        "from summarizer import summarize_by_language  # 요약 모듈 가져오기\n",
        "\n",
        "def main():\n",
        "    apply_css()\n",
        "    show_header()\n",
        "\n",
        "    url = st.text_input(\"Paste YouTube video URL here\")\n",
        "    if st.button(\"Go\"):\n",
        "        st.write(f\"📺 You entered: {url}\")\n",
        "        with st.spinner(\"🔎댓글을 분류중입니다... 잠시만 기다려주세요\"):\n",
        "            df = get_comments(url)\n",
        "            if df.empty or 'text' not in df.columns:\n",
        "                st.warning(\"No comments found or 'text' field missing.\")\n",
        "                return\n",
        "            classify_and_store(df, st.session_state)\n",
        "\n",
        "    if 'df' in st.session_state:\n",
        "        df = st.session_state.df\n",
        "        st.success(\"댓글 수집 및 언어 분류 완료!\")\n",
        "        st.write(\"총 댓글 수:\", len(df))\n",
        "\n",
        "        languages = df['lang'].unique().tolist()\n",
        "        language_options = [langcodes.Language.get(code).display_name() for code in languages]\n",
        "\n",
        "        selected_langs = st.multiselect(\"언어를 선택하세요\", options=language_options, default=language_options)\n",
        "        selected_lang_codes = [code for code in languages if langcodes.Language.get(code).display_name() in selected_langs]\n",
        "        filtered_df = df[df['lang'].isin(selected_lang_codes)]\n",
        "\n",
        "        if not filtered_df.empty:\n",
        "            st.write(filtered_df[['언어', 'text']])\n",
        "\n",
        "            # ✅ 요약하기 버튼\n",
        "            if st.button(\"요약하기\"):\n",
        "                st.session_state.summary = summarize_by_language(filtered_df)\n",
        "\n",
        "        else:\n",
        "            st.warning(\"선택한 언어에 해당하는 댓글이 없습니다.\")\n",
        "\n",
        "        # ✅ 요약 결과 출력 (버튼 클릭 이후에만 표시됨)\n",
        "        if 'summary' in st.session_state and st.session_state.summary:\n",
        "            for code in selected_lang_codes:\n",
        "                summary = st.session_state.summary.get(code)\n",
        "                lang_name = langcodes.Language.get(code).display_name()\n",
        "\n",
        "                st.markdown(f\"### 💬 {lang_name} 요약\")\n",
        "                if summary:\n",
        "                    st.markdown(f\"**요약:** {summary.get('summary', '(요약 없음)')}\")\n",
        "                    st.markdown(f\"**키워드:** {summary.get('keywords', '(키워드 없음)')}\")\n",
        "                else:\n",
        "                    st.info(\"요약 결과가 없습니다.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqTETxsoRnUv"
      },
      "source": [
        "메인 실행 파일 - 요약 전용 파일 + 감정 분석 전용 파일 적용 버전"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에 '!pip install keybert sentence-transformers transformers --quiet'가 실행되어 있어야 함"
      ],
      "metadata": {
        "id": "BblAB5IY574E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJJ7Jzi_R1ka",
        "outputId": "66ab61fa-b3dc-454c-b8f5-c9a6d5646720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing streamlit_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import langcodes\n",
        "from design import apply_css, show_header\n",
        "from logic import get_comments\n",
        "from classifier import classify_and_store\n",
        "from summarizer import summarize_by_language\n",
        "from sentiment import analyze_sentiment  # ✅ 감정 분석 추가\n",
        "\n",
        "def main():\n",
        "    apply_css()\n",
        "    show_header()\n",
        "\n",
        "    url = st.text_input(\"Paste YouTube video URL here\")\n",
        "    if st.button(\"Go\"):\n",
        "        st.write(f\"\\U0001F4FA You entered: {url}\")\n",
        "        with st.spinner(\"\\U0001F50E댓글을 분류중입니다... 잠시만 기다려주세요\"):\n",
        "            df = get_comments(url)\n",
        "            if df.empty or 'text' not in df.columns:\n",
        "                st.warning(\"No comments found or 'text' field missing.\")\n",
        "                return\n",
        "            classify_and_store(df, st.session_state)\n",
        "\n",
        "    if 'df' in st.session_state:\n",
        "        df = st.session_state.df\n",
        "        st.success(\"댓글 수집 및 언어 분류 완료!\")\n",
        "        st.write(\"총 댓글 수:\", len(df))\n",
        "\n",
        "        languages = df['lang'].unique().tolist()\n",
        "        language_options = [langcodes.Language.get(code).display_name() for code in languages]\n",
        "\n",
        "        selected_langs = st.multiselect(\"언어를 선택하세요\", options=language_options, default=language_options)\n",
        "        selected_lang_codes = [code for code in languages if langcodes.Language.get(code).display_name() in selected_langs]\n",
        "        filtered_df = df[df['lang'].isin(selected_lang_codes)]\n",
        "\n",
        "        if not filtered_df.empty:\n",
        "            st.write(filtered_df[['언어', 'text']])\n",
        "\n",
        "            # ✅ 감정 분석 버튼 추가\n",
        "            if st.button(\"감정 분석하기\"):\n",
        "                with st.spinner(\"\\U0001F914 감정을 분석 중입니다...\"):\n",
        "                    df_with_sentiment = analyze_sentiment(filtered_df)\n",
        "                    st.session_state.df = df_with_sentiment  # 업데이트\n",
        "                    st.success(\"감정 분석 완료!\")\n",
        "                    st.dataframe(df_with_sentiment[['언어', 'text', 'sentiment_kor']])\n",
        "\n",
        "            # ✅ 요약 버튼 추가\n",
        "            if st.button(\"요약하기\"):\n",
        "                with st.spinner(\"\\u23F3 언어별 요약 중입니다...\"):\n",
        "                    st.session_state.summary = summarize_by_language(filtered_df)\n",
        "\n",
        "                for lang_code in selected_lang_codes:\n",
        "                    summary = st.session_state.summary.get(lang_code)\n",
        "                    lang_label = langcodes.Language.get(lang_code).display_name()\n",
        "                    st.markdown(f\"### 💬 {lang_label} 요약\")\n",
        "                    if summary:\n",
        "                        st.markdown(f\"**요약:** {summary.get('summary', '(요약 없음)')}\")\n",
        "                        st.markdown(f\"**키워드:** {summary.get('keywords', '(키워드 없음)')}\")\n",
        "                    else:\n",
        "                        st.info(\"요약 결과가 없습니다.\")\n",
        "\n",
        "        else:\n",
        "            st.warning(\"선택한 언어에 해당하는 댓글이 없습니다.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________"
      ],
      "metadata": {
        "id": "_EnTQana6Fer"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TWEDbaTRL-Jx"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok  # pyngrok 라이브러리를 임포트하여 ngrok과 연동\n",
        "\n",
        "\n",
        "# ngrok 토큰 등록 (여기에 본인 ngrok 계정의 인증 토큰을 입력해야 함)\n",
        "ngrok.set_auth_token(\"\")\n",
        "\n",
        "\n",
        "\n",
        "# 연결할 포트를 지정하고, ngrok으로 해당 포트를 외부에서 접속 가능하게 연결\n",
        "port = 8501  # Streamlit의 기본 포트가 8501\n",
        "public_url = ngrok.connect(port)  # 포트 8501을 외부 접속용으로 공개\n",
        "print(f\"Public URL: {public_url}\")  # 생성된 public URL을 출력\n",
        "\n",
        "\n",
        "\n",
        "# Streamlit 앱 실행 (streamlit_app.py 파일을 실행하고, 지정된 포트로 서버를 시작)\n",
        "# &는 백그라운드 실행 (Colab 같은 환경에서는 필요)\n",
        "!streamlit run streamlit_app.py --server.port {port} &\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}